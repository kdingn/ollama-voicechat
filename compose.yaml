version: "3.8"

services:
  llm-api:
    container_name: ollama
    build:
      context: .
      dockerfile: dockerfile.ollama.cpu
    ports:
      - "11434:11434"

  speech-api:
    container_name: aivisspeech
    image: ghcr.io/aivis-project/aivisspeech-engine:cpu-latest
    entrypoint: ["/entrypoint.sh"]
    command:
      [
        "gosu",
        "user",
        "/opt/python/bin/poetry",
        "run",
        "python",
        "./run.py",
        "--host",
        "0.0.0.0",
      ]
    ports:
      - "10101:10101"
